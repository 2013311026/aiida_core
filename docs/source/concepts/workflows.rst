.. _workflows:

*********
Workflows
*********

Workflows are a central concept in AiiDA that allow you to string together multiple calculations that encodes the logic of a typical scientific workflow.
In this section, we explain what workflows are, how they can be used and run.
Finally, we will detail some best practices when designing workflows.

.. _workchains_workfunctions:

Workchains and workfunctions
============================

At the core of a workflow, is the logic that defines the sequence of calculations that need to be executed to get from the initial inputs to the desired final answer.
The way to encode this workflow logic in AiiDA, are workchains and workfunctions.
By chaining workchains and workfunctions together, that each can run calculations within them, we can define a workflow.

Workfunctions
-------------
To illustrate how workfunctions and workchains are defined, how they are used and when to use which, we will consider the following trivial example.
Given three integers, sum the first two and then multiply the result by the third.
In plain python code, the solution would look something like the following:

.. include:: include/snippets/workflows/workfunctions/example_problem_plain_python.py
    :code: python

This simple code snippet achieved the goal of getting the desired result, however, the provenance is lost.
There is no connection between the output of the functions and their inputs.
The remedy to this problem is the ``workfunction``.
The ``workfunction`` in AiiDA is a decorator that transforms a regular python function in a workfunction, which automatically stores the provenance of its output.
The following snippet shows how little one has to change the initial solution to add automatic provenance keeping:

.. include:: include/snippets/workflows/workfunctions/example_problem_workfunction_decorator.py
    :code: python

The only thing we had to do is to decorate the two functions with the ``workfunction`` decorator.
Adding the decorator tells AiiDA that the provenance for this function when it is executed should be stored.
This means linking up the inputs and the outputs for a calculation node, which represents the function that was executed.
The final change that has to be performed is to make the inputs and the outputs storable.
In this example, they are plain python integer types, which cannot be stored in the database.
To solve this, one only has to wrap them in the ``Int`` class, which makes them storable in the database:

.. include:: include/snippets/workflows/workfunctions/example_problem_workfunction_data_types.py
    :code: python

The only difference with the previous snippet is that all inputs and outputs have been wrapped in the ``Int`` class.
With these trivial changes, the full provenance of the result is maintained and looks like this:

.. figure:: include/images/workfunction_provenance.png

    The provenance generated by the workfunction example

To summarize: to write a workflow that automatically stores the provenance, one only has to decorate the functions with the ``workfunction`` decorator and make sure that the inputs and outputs are wrapped in database storable types.

Workchains
----------
Now that we have demonstrated how easily ``workfunctions`` can be used to write your workflow that automatically keeps the provenance, it is time to confess that workfunctions are not perfect and have their shortcomings.
In the simple example of adding and multiplying numbers, the time to execute the functions is very short, but imagine that you are performing a more costly calculation, e.g. you want to run an actual ``JobCalculation`` that will be submitted to the scheduler and may run for a long time.
If anywhere during the chain, the workflow is interrupted, for whatever reason, all progress is lost.
There are no 'checkpoints', so to speak, by simply chaining workfunctions together.

But fret not!
To tackle this problem, AiiDA defines the concept of the workchain.
As the name suggests, this construct is a way to chain multiple logical steps of a workflow together in a way that allows to save the progress between those steps as soon as they are successfully completed.
The workchain is therefore the preferred solution for parts of the workflow that involve more expensive and complex calculations.
To define a workchain, AiiDA implements the ``WorkChain`` class.

If we were to reimplement our workfunction solution of the simple example problem of the previous section, but this time using a workchain, it would look something like the following: 

.. include:: include/snippets/workflows/workchains/example_problem_workchain.py
    :code: python

There is a lot going on in this snippet, so let's tackle it line by line.
Firstly, a ``WorkChain`` is a class and to create your own workchain, you subclass it and give it your own name, like ``AddAndMultiplyWorkChain`` in the example.
You can pick any name that is a valid python class name.
The most important method of the ``WorkChain`` class, is the ``define`` class method.
Here you define, what inputs it takes, what outputs it will generate and the 'logic' that will be executed.
The class method takes two arguments:

 * ``cls`` this is the reference of the class itself and is mandatory for any class method
 * ``spec`` which is the 'specification'

.. note::
    Do not forget to add the line ``super(AddAndMultiplyWorkChain, self).define(spec)`` as the first line of the ``define`` method, where you replace the class name with the name of your workchain.
    This will call the ``define`` method of the parent class, which is necessary for the workchain to work properly

As the name suggests, the ``spec`` can be used to specify the properties of the workchain.
For example, it can be used to define inputs that the workchain takes.
In our example, we need to be able to pass three integers as input, so we define those in the spec by calling `spec.input()`.
The first argument is the name of the input.
Additionally, as we have done here, you can specify which types are valid for that particular input.
Since we expect integers, we specify that the valid type is the database storable ``Int`` class.
Input validation is just one of the advantages of the ``WorkChain`` over the workfunction that we can already see here.

The outputs are defined in a similar manner, calling `spec.output()` you can declare a particular output that the workchain will or is expected to have.
Be wary that if you define an output, but do not actually add it during the exection, at the end of the workchain, the validation will fail as by default all defined outputs are assumed to be required.
If you want to specify an output that is optional, you can pass the keyword argument ``required=False``.

The final part of the spec definition is the ``outline``.
This is where you specify the 'logic' of the workchain.
Since this example is rather contrived, in this case it is just a list of three functions calls ``add``, ``multiply`` and ``results``.
However, the outline also supports logical constructs, like ``if`` conditionals ``while`` loops and ``return`` statements.
Refer to the advanced :ref:`workchain section <process_spec>` to see all the possibilities the ``outline`` provides.

The only thing that remains, is to implement the methods that we added to the ``outline``.
Since they are class instance methods, they only take one argument ``self``.
Besides that rule, you can add any valid python code in the method that you want.
The goal of the ``add`` method is to take the inputs ``a`` and ``b`` that are passed to the workchain and sum them.
The inputs passed to the workchain are stored in the ``inputs`` attribute as an attribute dictionary.
Therefore, to get the ``a`` input for example, you can call ``self.inputs.a``.

After we summed ``a`` and ``b``, we need to be able to store the temporary result and pass it to the next step in the ``outline``, in this case the ``multiply`` method.
For this purpose, each workchain has a context, which can be addressed at ``self.ctx``.
It is a dictionary that is persisted between workchain steps and can therefore be used to pass information and data between outline steps.
Since it is a dictionary, we can store the sum of ``a`` and ``b`` by assigning it to a key of our choice.
Again, any valid python key name, as long as it does do not contain a period, is fair game.
Note that we do not have to return anything, as soon as the function ends, the workchain will save its state, including the result we just stored in the context and go to the next step, the ``multiply`` method.
By now you should be familiar with what you see.
We retrieve the sum we computed in the ``add`` method, multiply it by the ``c`` input integer and store it under the ``product`` key in the context.

The final step ``results`` adds the product as an official output of the workchain by calling ``self.out()``.
The first argument is the name of the output, which will also be used for the linkname in the provenance graph and the second argument is the actual value.
Note that since it again has to be database storable, we wrap the product in the ``Int`` class.
The resulting provenance when we run this workchain looks like this:

.. figure:: include/images/workchain_provenance.png

    The provenance generated by the workchain example

This is very quick overview of how a workchain works but of course it has a lot more features.
To learn how to write workchains for real life problems, continue reading at the :ref:`workflow development <workflow_development>` section.

When to use which
-----------------
Now that we know how the two workflow components, workflows and workchains, work in AiiDA, you might wonder: when should I use which one?
For simple operations that do not take long, the simplicity of the workfunction may be all you need, so by all means use it.
However, a good rule of thumb is that as soon as the code is expected to take longer, for example when you want to launch a ``JobCalculation``, it is always best to go for the ``WorkChain``.
The automatic checkpointing, which guarantess that work between steps is saved, becomes very important.
The workchain offers a lot more features than checkpointing that may make it more preferable over the workfunction, which you can read about in the :ref:`workflow development <workflow_development>` section.


.. _running_workflows:

Running workflows
=================

Run
---
Without realizing it, in the :ref:`introductory section on workfunctions and workchains <workchains_workfunctions>`, we already saw how a workfunction can be ran.
We can run a workfunction in exactly the same manner as you would run any other python function.
Simply call the function with the desired inputs and it will be executed, while AiiDA makes sure to store the provenance automatically in the background.
You can run workfunctions from anywhere, also inside an outline step of a workchain.

Running a ``WorkChain`` on the other hand, is slightly different.
Since it is a class, it cannot be 'run' directly like a function.
Instead, we have to 'launch' it.
This is done by passing it to the ``run`` function:

.. include:: include/snippets/workflows/workchains/run_workchain_keyword.py
    :code: python

As you can see, the ``run`` function can be imported from ``aiida.work.launch``.
To launch the workchain (in this example we use the ``AddAndMultiplyWorkChain`` from the previous section), we simply call the ``run`` function with the workchain as the first argument, followed by the inputs as keyword arguments.
Note that the keys used for each input have to correspond to the name of the inputs defined in the spec of the workchain.
One can also define the inputs in a dictionary and then use the standard python expansion method to automatically unwrap the dictionary into keyword arguments, as is shown here:

.. include:: include/snippets/workflows/workchains/run_workchain_expand.py
    :code: python

After the workchain's execution is finished, the result is returned, which is a dictionary of its outputs.
In this example the variable ``result`` will therefore be equal to ``{'result': 9}``.
If you would also like to get a reference of the node that represents the ``WorkChain`` in the database, one can use the ``run_get_node`` or ``run_get_pid`` functions: 

.. include:: include/snippets/workflows/workchains/run_workchain_get_node_pid.py
    :code: python

For the former, the ``node`` will be the ``WorkCalculation`` node that is used to represent the workchain in the database, whereas for the latter, the ``pid`` is the pk of that same node.

Submit
------
The launch functions, ``run``, ``run_get_node`` and ``run_get_pid``, described in the previous section, will execute the process in a blocking manner.
That is to say that the interpreter in which you launch the process will be blocked until that process is completed.
This might not necessarily be what you want.
Imagine for example that you are launching a workchain that will take a long time to complete.
The interpreter will be blocked the whole time and cannot do anything else.
To circumvent this problem, you can also ``submit`` a process, for example a workchain:

.. include:: include/snippets/workflows/workchains/run_workchain_submit.py
    :code: python

The ``submit`` function will launch the process and send it to the daemon, who will take care of running it to the end.
This way the interpreter is freed and regains control immediately.
The return value of the ``submit`` call is the node that represents the process in the database.
Note that besides the change in behavior, the syntax for passing the inputs to ``submit`` is exactly the same as for the ``run`` launch function and its siblings.

There is one limitation to the use of the ``run`` and ``submit`` launchers.
They cannot be used within the steps of a ``WorkChain`` itself.
Instead, the ``WorkChain`` class has its own ``submit`` method that should be used.

.. include:: include/snippets/workflows/workchains/run_workchain_submit_internal.py
    :code: python

In this example, we launch another instance of the ``AddAndMultiplyWorkChain`` from within the ``AddAndMultiplyWorkChain`` itself.
Note that the only difference is that instead of using the free function ``submit``, we use the class instance method ``self.submit``.

.. _running_workflows_process_builder:

Process builder
---------------
There is one final way of launching a process, whether it be a ``WorkChain`` or a ``JobCalculation``.
Each process has a method called ``get_builder`` which will return an instance of the ``ProcessBuilder`` customised for that particular ``Process`` class.
The builder knows exactly which inputs the process takes and expects and is therefore ideal for interactive usage.
For details on how to instantiate and populate a ``ProcessBuilder`` instance please refer to :ref:`the process builder section<process_builder>`.

One you have constructed your builder and inserted all the inputs, you can pass it to the launch functions like we did in the previous two sections:

.. include:: include/snippets/workflows/workchains/run_workchain_submit_internal.py
    :code: python

Note that you are free to use this method of launching processes in normal scripts, but the builder really is designed for use in an interactive shell.


Monitoring workflows
====================

ISSUE#1129


.. _workflow_development:

Workflow development
====================

ISSUE#1130


.. _process_spec:

The process specification
-------------------------

This will explain details of the ``ProcessSpec``.


.. _expose_inputs_outputs:

Exposing inputs and outputs
---------------------------

When creating complex workflows, it is a good idea to split them up into smaller, modular parts. At the lowest level, each workflow should perform exactly one task. These workflows can then be wrapped together by a "parent" workflow to create a larger logical unit.

In order to make this approach manageable, it needs to be as simple as possible to glue together multiple workflows in a larger parent workflow. For this reason, AiiDA provides the *expose* functionality, which will be explained here.

Consider the following example workchain, which simply takes a few inputs and returns them again as outputs:

.. include:: include/snippets/workflows/expose_inputs/child.py
    :code: python

As a first example, we will implement a thin wrapper workflow, which simply forwards its inputs to ``ChildWorkChain``, and forwards the outputs of the child to its outputs:

.. include:: include/snippets/workflows/expose_inputs/simple_parent.py
    :code: python

In the ``define`` method of this simple parent workchain, we use the :meth:`.expose_inputs` and :meth:`.expose_outputs`. This creates the corresponding input and output ports in the parent workchain.

Additionally, AiiDA remembers which inputs and outputs were exposed from that particular workchain class. This is used when calling the child in the ``run_child`` method. The :meth:`~aiida.work.Process.exposed_inputs` method returns a dictionary of inputs that the parent received which were exposed from the child, and so it can be used to pass these on to the child.

Finally, in the ``finalize`` method, we use :meth:`~aiida.work.Process.exposed_outputs` to retrieve the outputs of the child which were exposed to the parent. Using :meth:`~aiida.work.Process.out_many`, these outputs are added to the outputs of the parent workchain.

This workchain can now be run in exactly the same way as the child itself:

.. include:: include/snippets/workflows/expose_inputs/run_simple.py
    :code: python

Next, we will see how a more complex parent workchain can be created by using the additional features of the expose functionality. The following workchain launches two children. These children share the input ``a``, but have different ``b`` and ``c``. The output ``e`` will be taken only from the first child, whereas ``d`` and ``f`` are taken from both children. In order to avoid name conflicts, we need to create a *namespace* for each of the two children, where the inputs and outputs which are not shared are stored. Our goal is that the workflow can be called as follows:

.. include:: include/snippets/workflows/expose_inputs/run_complex.py
    :code: python

This is achieved by the following workflow. In the next section, we will explain each of the steps.

.. include:: include/snippets/workflows/expose_inputs/complex_parent.py
    :code: python

First of all, we want to expose the ``a`` input and the ``e`` output at the top-level. For this, we again use :meth:`.expose_inputs` and :meth:`.expose_outputs`, but with the optional keyword ``include``. This specifies a list of keys, and only inputs or outputs which are in that list will be exposed. So by passing ``include=['a']`` to :meth:`.expose_inputs`, only the input ``a`` is exposed.

Additionally, we want to expose the inputs ``b`` and ``c`` (outputs ``d`` and ``f``), but in a namespace specific for each of the two children. For this purpose, we pass the ``namespace`` parameter to the expose functions. However, since we now shouldn't expose ``a`` (``e``) again, we use the ``exclude`` keyword, which specifies a list of keys that will not be exposed.

When calling the children, we again use the :meth:`~aiida.work.Process.exposed_inputs` method to forward the exposed inputs. Since the inputs ``b`` and ``c`` are now in a specific namespace, we need to pass this namespace as an additional parameter. By default, :meth:`~aiida.work.Process.exposed_inputs` will search through all the parent namespaces of the given namespace to search for input, as shown in the call for ``child_1``. If the same input key exists in multiple namespaces, the input in the lowest namespace takes precedence. It's also possible to disable this behavior, and instead search only in the explicit namespace that was passed. This is done by setting ``agglomerate=False``, as shown in the call to ``child_2``. Of course, we then need to explicitly pass the input ``a``.

Finally, we use :meth:`~aiida.work.Process.exposed_outputs` and :meth:`~aiida.work.Process.out_many` to forward the outputs of the children to the outputs of the parent. Again, the ``namespace`` and ``agglomerate`` options can be used to select which outputs are returned by the :meth:`~aiida.work.Process.exposed_outputs` method.
